# -*- coding: utf-8 -*-
"""Diabatetes Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N93ifI2jnysjuYjRIiiYQFAwtImS0YDn
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

#loading the datasets
diabetes_dataset = pd.read_csv('/content/diabetes.csv');

#printing the first 5 rows of the dataset
diabetes_dataset.head()

#number of rows and columns in this dataset
diabetes_dataset.shape

#getting the statistical measures of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts() #check how many values are there for the given column

"""0--> Non-diabetic
1-->diabetic
"""



diabetes_dataset.groupby('Outcome').mean()

"""If You're dropping a coloumn axis =1 and if you are dropping a row axis=0"""

#seperating the data and levels
X = diabetes_dataset.drop(columns = 'Outcome', axis=1)
Y = diabetes_dataset['Outcome']

print(X)

print(Y)

"""Data Standarization"""

scaler = StandardScaler()

scaler.fit(X)

#for having data in same range
standarized_data = scaler.transform(X)

print(standarized_data)

X = standarized_data
Y = diabetes_dataset['Outcome']

print(X)
print(Y)

"""Train Test Split

test_size = 0.2 means 20% of data will be used as test data and 80% data will be in test data.
Statify - It is used so that similar proportion of output go into test data and train data
Random State -
"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""Training the model"""

classifier = svm.SVC(kernel='linear')

#training the support vector machine classifier
classifier.fit(X_train,Y_train)

"""Model Evaluation

Finding Accuracy Score
"""

#accuracy score on the training data
X_train_prediction = classifier.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction,Y_train)

print('Accuracy Score of the training data : ',training_data_accuracy)

"""Accuracy Score on test data"""

X_test_prediction = classifier.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediction,Y_test)

print('Accuracy score of the text data:',test_data_accuracy)

"""Making a predictive system"""

input_data = (9,119,80,35,0,29,0.263,29)
input_data = (9,119,80,35,0,29,0.263,29)

#changing the data into numpy array
input_data_as_numpy_array = np.asarray(input_data) #it will convert the list into numpy array

#reshaping the array as we are prdicting for instance
#this will tell the model that we are not prdicting for 768 instances we are just predicting for 1 instances
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

#standarize the input data(same manner as we have done with the tarining data)
std_data = scaler.transform(input_data_reshaped)
print(std_data)

predictions = classifier.predict(std_data)
print(predictions)
#this will tell the model that we are not prdicting for 768 instances we are just predicting for 1 instances
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

#standarize the input data(same manner as we have done with the tarining data)
std_data = scaler.transform(input_data_reshaped)
print(std_data)

predictions = classifier.predict(std_data)
print(predictions)

if(predictions[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')